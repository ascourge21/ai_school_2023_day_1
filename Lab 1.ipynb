{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aae85ce9",
   "metadata": {},
   "source": [
    "# Exercise 1 \n",
    "- Simulate the position of dart throws by two players using the following criteria:\n",
    "    - Player 1: mean x, y position = (0, 0), cov matrix = [[1, 0]  [0, 2]]\n",
    "    - Player 2: mean x, y position = (2, 1), cov matrix = [[3, -2], [-2, 2]]\n",
    "- Draw contourplot displaying the joint probability distributions\n",
    "- Generate 200 samples each for both players and plot those -> use `numpy.random.choice`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b58ca66",
   "metadata": {},
   "source": [
    "# Exercise 2 \n",
    "- Label points from player 1 as `0` and points from player 2 as `1`. \n",
    "- Use `logistic regression` from scipy to classify these points.\n",
    "    - Check performance using `accuracy_score` from `sklearn.metrics`. \n",
    "- Implement your own logistic regression by filling out the functions in the skeleton below.\n",
    "- Implement the gradient function using:\n",
    "    - The direct method - find out the actual function [from the lecture slides](https://docs.google.com/presentation/d/1fnftEMoecsjflXaIkFUSDcbVg2ksqd9EiOOCC-UwPkU/edit?usp=sharing): \n",
    "    - Numeric/analytical method by computing numeric gradients\n",
    "- Use any other ML method to achieve better performance - SVM, Neural Networks, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0511cc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill this out\n",
    "\n",
    "class LogisticRegressionCustom:\n",
    "    \"\"\"\n",
    "    Implement the functions that have pass written.\n",
    "    \"\"\"\n",
    "    T = 1e5\n",
    "    \n",
    "    def get_prob(self, X, beta):                            \n",
    "        pass\n",
    "\n",
    "    def loss(self, X, beta, y):\n",
    "        pass\n",
    "    \n",
    "    def gradient(self, X, beta, y):\n",
    "        pass\n",
    "    \n",
    "    def gradient_descent_fit(self, X, beta, y):\n",
    "        count = 0\n",
    "        beta_ = np.copy(beta)\n",
    "        while count < self.T:\n",
    "            count += 1\n",
    "            grad = self.gradient(X, beta_, y)\n",
    "            beta_ -= LR * grad\n",
    "            if np.sum(np.abs(grad)) < thresh:\n",
    "                break\n",
    "        return beta_\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.beta = np.zeros((X.shape[1] + 1))\n",
    "        self.beta += rng.randn(X.shape[1] + 1)\n",
    "        intercept_X = np.ones((X.shape[0], 1))\n",
    "        self.X = np.concatenate((intercept_X, X), axis=1)\n",
    "        self.y = y\n",
    "        \n",
    "        fitted_beta = self.grad_descent_fit(\n",
    "            self.X, self.beta, self.y\n",
    "        )\n",
    "        self.beta = fitted_beta\n",
    "        return self.beta\n",
    "    \n",
    "    def predict(self, X):\n",
    "        pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
